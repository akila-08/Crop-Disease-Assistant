{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAPPING IMAGE AND CSV FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in c:\\users\\samridhaa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.13.0)\n",
      "Requirement already satisfied: numpy<3,>=1.24.3 in c:\\users\\samridhaa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn) (1.26.3)\n",
      "Requirement already satisfied: scipy<2,>=1.10.1 in c:\\users\\samridhaa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn) (1.13.0)\n",
      "Requirement already satisfied: scikit-learn<2,>=1.3.2 in c:\\users\\samridhaa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn) (1.4.2)\n",
      "Requirement already satisfied: sklearn-compat<1,>=0.1 in c:\\users\\samridhaa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn) (0.1.3)\n",
      "Requirement already satisfied: joblib<2,>=1.1.1 in c:\\users\\samridhaa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn) (1.4.0)\n",
      "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in c:\\users\\samridhaa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn) (3.4.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          N   P   K  temperature   humidity        ph    rainfall  \\\n",
      "0        90  42  43    20.879744  82.002744  6.502985  202.935536   \n",
      "100      85  58  41    21.770462  80.319644  7.038096  226.655537   \n",
      "200      60  55  44    23.004459  82.320763  7.840207  263.964248   \n",
      "300      74  35  40    26.491096  80.158363  6.980401  242.864034   \n",
      "400      78  42  42    20.130175  81.604873  7.628473  262.717340   \n",
      "...     ...  ..  ..          ...        ...       ...         ...   \n",
      "219500  107  34  32    26.774637  66.413269  6.780064  177.774507   \n",
      "219600   99  15  27    27.417112  56.636362  6.086922  127.924610   \n",
      "219700  118  33  30    24.131797  67.225123  6.362608  173.322839   \n",
      "219800  117  32  34    26.272418  52.127394  6.758793  127.175293   \n",
      "219900  104  18  30    23.603016  60.396475  6.779833  140.937041   \n",
      "\n",
      "                     Label  \n",
      "0       Apple___Apple_scab  \n",
      "100     Apple___Apple_scab  \n",
      "200     Apple___Apple_scab  \n",
      "300     Apple___Apple_scab  \n",
      "400     Apple___Apple_scab  \n",
      "...                    ...  \n",
      "219500    Potato___healthy  \n",
      "219600    Potato___healthy  \n",
      "219700    Potato___healthy  \n",
      "219800    Potato___healthy  \n",
      "219900    Potato___healthy  \n",
      "\n",
      "[2200 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r\"C:\\Users\\Samridhaa\\OneDrive\\Desktop\\DL Package\\plant_disease_multimodal_dataset.csv\")\n",
    "\n",
    "columns_to_remove = [\"Mapped Label\", \"Image Path\"]  \n",
    "df = df.drop(columns=columns_to_remove)\n",
    "\n",
    "# Remove exact duplicate rows\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "print(df)  # Check the new dataset size\n",
    "df.to_csv(\"updated_file.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print((df[\"Label\"] == \"Potato___healthy\").sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          N   P   K  temperature   humidity        ph    rainfall  \\\n",
      "0        90  42  43    20.879744  82.002744  6.502985  202.935536   \n",
      "100      85  58  41    21.770462  80.319644  7.038096  226.655537   \n",
      "200      60  55  44    23.004459  82.320763  7.840207  263.964248   \n",
      "300      74  35  40    26.491096  80.158363  6.980401  242.864034   \n",
      "400      78  42  42    20.130175  81.604873  7.628473  262.717340   \n",
      "...     ...  ..  ..          ...        ...       ...         ...   \n",
      "219500  107  34  32    26.774637  66.413269  6.780064  177.774507   \n",
      "219600   99  15  27    27.417112  56.636362  6.086922  127.924610   \n",
      "219700  118  33  30    24.131797  67.225123  6.362608  173.322839   \n",
      "219800  117  32  34    26.272418  52.127394  6.758793  127.175293   \n",
      "219900  104  18  30    23.603016  60.396475  6.779833  140.937041   \n",
      "\n",
      "                     Label  \n",
      "0       Apple___Apple_scab  \n",
      "100     Apple___Apple_scab  \n",
      "200     Apple___Apple_scab  \n",
      "300     Apple___Apple_scab  \n",
      "400     Apple___Apple_scab  \n",
      "...                    ...  \n",
      "219500    Potato___healthy  \n",
      "219600    Potato___healthy  \n",
      "219700    Potato___healthy  \n",
      "219800    Potato___healthy  \n",
      "219900    Potato___healthy  \n",
      "\n",
      "[2200 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… New CSV saved with 2200 images\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define dataset path\n",
    "dataset_folder = r\"c:\\users\\samridhaa\\onedrive\\desktop\\dl package\\color\"\n",
    "\n",
    "# Get all image paths\n",
    "image_paths = []\n",
    "labels = []\n",
    "\n",
    "for root, _, files in os.walk(dataset_folder):\n",
    "    for file in files:\n",
    "        if file.endswith((\".jpg\", \".png\", \".jpeg\",\".JPG\",\".PNG\",\".JPEG\")):  # Adjust extensions as needed\n",
    "            full_path = os.path.abspath(os.path.join(root, file))  # Ensure full absolute path\n",
    "            image_paths.append(full_path)\n",
    "\n",
    "            # Extract folder name as label\n",
    "            label = os.path.basename(root)  \n",
    "            labels.append(label)\n",
    "\n",
    "# Create new CSV\n",
    "df = pd.DataFrame({\"image_path\": image_paths, \"Label\": labels})\n",
    "\n",
    "# Save CSV\n",
    "df.to_csv(\"new_mapped_data.csv\", index=False)\n",
    "print(f\"âœ… New CSV saved with {len(df)} images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2200"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_file = r\"C:\\Users\\Samridhaa\\OneDrive\\Desktop\\DL Package\\new_mapped_data.csv\"\n",
    "df = pd.read_csv(csv_file)\n",
    "df[\"image_path\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully merged! Saved as mapped_data_with_images.csv\n",
      "    N   P   K  temperature   humidity        ph    rainfall  \\\n",
      "0  90  42  43    20.879744  82.002744  6.502985  202.935536   \n",
      "1  79  42  37    24.873007  82.840226  6.587919  295.609449   \n",
      "2  67  45  38    22.727910  82.170688  7.300411  260.887506   \n",
      "3  61  52  41    24.976695  83.891805  6.880431  204.800185   \n",
      "4  91  56  37    23.431916  80.568878  6.363472  269.503916   \n",
      "\n",
      "                Label                                         image_path  \n",
      "0  Apple___Apple_scab  c:\\users\\samridhaa\\onedrive\\desktop\\dl package...  \n",
      "1  Apple___Apple_scab  c:\\users\\samridhaa\\onedrive\\desktop\\dl package...  \n",
      "2  Apple___Apple_scab  c:\\users\\samridhaa\\onedrive\\desktop\\dl package...  \n",
      "3  Apple___Apple_scab  c:\\users\\samridhaa\\onedrive\\desktop\\dl package...  \n",
      "4  Apple___Apple_scab  c:\\users\\samridhaa\\onedrive\\desktop\\dl package...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "updated_csv_file = r\"C:\\Users\\Samridhaa\\OneDrive\\Desktop\\DL Package\\updated_file.csv\"\n",
    "new_mapped_csv = \"new_mapped_data.csv\" \n",
    "final_csv_output = \"mapped_data_with_images.csv\"\n",
    "\n",
    "\n",
    "df_numerical = pd.read_csv(updated_csv_file)  \n",
    "df_images = pd.read_csv(new_mapped_csv)  \n",
    "\n",
    "\n",
    "if len(df_numerical) != 2200:\n",
    "    print(f\"Error: updated_file.csv has {len(df_numerical)} rows, expected 2200.\")\n",
    "if len(df_images) != 2200:\n",
    "    print(f\"Error: new_mapped_data.csv has {len(df_images)} rows, expected 2200.\")\n",
    "\n",
    "\n",
    "df_numerical = df_numerical.sort_values(by=\"Label\").reset_index(drop=True)\n",
    "df_images = df_images.sort_values(by=\"Label\").reset_index(drop=True)\n",
    "\n",
    "\n",
    "df_numerical[\"image_path\"] = df_images[\"image_path\"]\n",
    "df_numerical.to_csv(final_csv_output, index=False)\n",
    "\n",
    "print(f\"Successfully merged! Saved as {final_csv_output}\")\n",
    "print(df_numerical.head())  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2200"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_file = r\"C:\\Users\\Samridhaa\\OneDrive\\Desktop\\DL Package\\mapped_data_with_images.csv\"\n",
    "df = pd.read_csv(csv_file)\n",
    "df[\"image_path\"].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMAGE PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Shape: torch.Size([32, 3, 224, 224])\n",
      "Sample Labels: ('Grape___healthy', 'Potato___healthy', 'Pepper,_bell___Bacterial_spot', 'Corn_(maize)___healthy', 'Grape___Leaf_blight_(Isariopsis_Leaf_Spot)')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "\n",
    "# Define Image Transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize images\n",
    "    transforms.ToTensor(),          # Convert to Tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize\n",
    "])\n",
    "\n",
    "# Custom Dataset Class for Image + CSV Data\n",
    "class CropDiseaseDataset(Dataset):\n",
    "    def __init__(self, csv_file):\n",
    "        self.df = pd.read_csv(csv_file)  \n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.df.iloc[idx][\"image_path\"]\n",
    "        label = self.df.iloc[idx][\"Label\"]  # Crop Disease Label\n",
    "\n",
    "        # Load Image using OpenCV (Faster than PIL)\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "        image = Image.fromarray(image)  # Convert to PIL Image\n",
    "\n",
    "        image = self.transform(image)  # Apply transformations\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# Load Dataset\n",
    "csv_file = \"mapped_data_with_images.csv\"\n",
    "dataset = CropDiseaseDataset(csv_file)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Check if preprocessing works\n",
    "sample_image, sample_label = next(iter(dataloader))\n",
    "print(f\"Image Shape: {sample_image.shape}\")  \n",
    "print(f\"Sample Labels: {sample_label[:5]}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Train set size: 1760 images\n",
      "âœ… Test set size: 440 images\n",
      "Image Shape: torch.Size([8, 3, 224, 224])\n",
      "Numerical Features Shape: torch.Size([8, 7])\n",
      "Labels: tensor([12, 15,  2,  2, 11])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load CSV\n",
    "df = pd.read_csv(\"mapped_data_with_images.csv\")\n",
    "\n",
    "# Encode labels (convert category names to numbers)\n",
    "label_encoder = LabelEncoder()\n",
    "df[\"Label\"] = label_encoder.fit_transform(df[\"Label\"])  # Converts categorical labels to numerical\n",
    "\n",
    "# Split into train (80%) and test (20%)\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, stratify=df[\"Label\"], random_state=42)\n",
    "\n",
    "# Define data transformations (Resizing and Normalization for images)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  \n",
    "    transforms.ToTensor(),  \n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) \n",
    "])\n",
    "\n",
    "# Define the Dataset class\n",
    "class CropDiseaseDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.df.iloc[idx][\"image_path\"]\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = Image.fromarray(image)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # Select numerical features (excluding 'image_path' & 'Label')\n",
    "        numerical_features = self.df.iloc[idx, 0:-2]  \n",
    "        \n",
    "        #print(\"\\n\\t\",numerical_features)\n",
    "\n",
    "        # Convert all non-numeric values to NaN and then replace NaNs with mean values\n",
    "        numerical_features = pd.to_numeric(numerical_features, errors=\"coerce\").fillna(0)\n",
    "\n",
    "        # Convert to tensor\n",
    "        numerical_features = torch.tensor(numerical_features.values, dtype=torch.float32)\n",
    "\n",
    "        # Get encoded label\n",
    "        label = self.df.iloc[idx][\"Label\"]\n",
    "\n",
    "        return image, numerical_features, torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "\n",
    "# Create Train and Test Datasets\n",
    "train_dataset = CropDiseaseDataset(train_df, transform=transform)\n",
    "test_dataset = CropDiseaseDataset(test_df, transform=transform)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "# Print dataset sizes\n",
    "print(f\"âœ… Train set size: {len(train_dataset)} images\")\n",
    "print(f\"âœ… Test set size: {len(test_dataset)} images\")\n",
    "\n",
    "# Check the structure\n",
    "sample_img, sample_features, sample_label = next(iter(train_loader))\n",
    "print(f\"Image Shape: {sample_img.shape}\")  \n",
    "print(f\"Numerical Features Shape: {sample_features.shape}\")  \n",
    "print(f\"Labels: {sample_label[:5]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CropDiseaseModel(nn.Module):\n",
    "    def __init__(self, num_features, num_classes):\n",
    "        super(CropDiseaseModel, self).__init__()\n",
    "        self.num_features = num_features\n",
    "\n",
    "        self.image_feature_extractor = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.AdaptiveAvgPool2d((7, 7)),  # Reduce spatial size\n",
    "            nn.Flatten()  \n",
    "        )\n",
    "\n",
    "        self.fc1 = nn.Linear(num_features, 64)\n",
    "        \n",
    "        self.fc2 = nn.Linear(128 * 7 * 7 + 64, num_classes)  # Match flattened image feature size\n",
    "          \n",
    "    def forward(self, image, features):\n",
    "        img_features = self.image_feature_extractor(image)\n",
    "        img_features = img_features.view(img_features.shape[0], -1)  # Ensure it's properly flattened\n",
    "        num_features = F.relu(self.fc1(features))\n",
    "        combined_features = torch.cat((img_features, num_features), dim=1)\n",
    "        output = self.fc2(combined_features)\n",
    "        return output\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Device: cpu\n",
      "Images Device: cpu\n",
      "Features Device: cpu\n",
      "Labels Device: cpu\n",
      "Epoch 1, Loss: 178.5033\n",
      "Epoch 2, Loss: 21.1539\n",
      "Epoch 3, Loss: 9.5298\n",
      "Epoch 4, Loss: 9.0115\n",
      "Epoch 5, Loss: 8.8227\n",
      "Epoch 6, Loss: 10.0936\n",
      "Epoch 7, Loss: 4.1597\n",
      "Epoch 8, Loss: 4.0130\n",
      "Epoch 9, Loss: 6.8978\n",
      "Epoch 10, Loss: 0.5269\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# Move model to CPU explicitly\n",
    "model = CropDiseaseModel(num_features=7, num_classes=22)\n",
    "model.to(device)\n",
    "\n",
    "# Verify model parameters are on CPU\n",
    "assert next(model.parameters()).device == torch.device(\"cpu\"), \"Model is still on GPU!\"\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Model Device: {next(model.parameters()).device}\")\n",
    "\n",
    "for images, features, labels in train_loader:\n",
    "    print(f\"Images Device: {images.device}\")\n",
    "    print(f\"Features Device: {features.device}\")\n",
    "    print(f\"Labels Device: {labels.device}\")\n",
    "    break  # Just print once\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.ipc_collect()\n",
    "\n",
    "\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for images, features, labels in train_loader:\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        features = features.to(device, non_blocking=True)\n",
    "        labels = labels.to(device, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images, features)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()  # ðŸš¨ This was causing the CUDA OOM error\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9886363636363636\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "dataset = CropDiseaseDataset(\"mapped_data_with_images.csv\")\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "model.eval()\n",
    "preds, targets = [], []\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, features, labels in test_loader:\n",
    "        images, features = images.to(device), features.to(device)\n",
    "        outputs = model(images, features)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        preds.extend(predicted.cpu().numpy())\n",
    "        targets.extend(labels.cpu().numpy())\n",
    "\n",
    "print(\"Test Accuracy:\", accuracy_score(targets, preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model saved successfully as crop_disease_model.pth\n"
     ]
    }
   ],
   "source": [
    "# Save the trained model\n",
    "torch.save(model.state_dict(), \"crop_disease_model.pth\")\n",
    "print(\"âœ… Model saved successfully as crop_disease_model.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: Grape___Black_rot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Samridhaa\\AppData\\Local\\Temp\\ipykernel_32508\\1387586757.py:39: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(r\"C:\\Users\\Samridhaa\\OneDrive\\Desktop\\DL Package\\crop_disease_model.pth\", map_location=device))  # Update with correct model path\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "class CropDiseaseModel(nn.Module):\n",
    "    def __init__(self, num_features, num_classes):\n",
    "        super(CropDiseaseModel, self).__init__()\n",
    "        self.num_features = num_features\n",
    "\n",
    "        self.image_feature_extractor = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.AdaptiveAvgPool2d((7, 7)),  # Reduce spatial size\n",
    "            nn.Flatten()  \n",
    "        )\n",
    "\n",
    "        self.fc1 = nn.Linear(num_features, 64)\n",
    "        \n",
    "        self.fc2 = nn.Linear(128 * 7 * 7 + 64, num_classes)  # Match flattened image feature size\n",
    "          \n",
    "    def forward(self, image, features):\n",
    "        img_features = self.image_feature_extractor(image)\n",
    "        img_features = img_features.view(img_features.shape[0], -1)  # Ensure it's properly flattened\n",
    "        num_features = F.relu(self.fc1(features))\n",
    "        combined_features = torch.cat((img_features, num_features), dim=1)\n",
    "        output = self.fc2(combined_features)\n",
    "        return output\n",
    "\n",
    "# Load Model\n",
    "device = torch.device(\"cpu\")\n",
    "model = CropDiseaseModel(num_features=7, num_classes=22)  # Update with actual values\n",
    "model.load_state_dict(torch.load(r\"C:\\Users\\Samridhaa\\OneDrive\\Desktop\\DL Package\\crop_disease_model.pth\", map_location=device))  # Update with correct model path\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "\n",
    "# Image Preprocessing\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "def predict(image_path):\n",
    "    # Load image\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert to RGB\n",
    "    image = Image.fromarray(image)\n",
    "    \n",
    "    # Apply transformations\n",
    "    image = transform(image).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "    # Dummy numerical features (replace with real ones if available)\n",
    "    numerical_features = torch.zeros((1, 7), dtype=torch.float32)\n",
    "\n",
    "    # Move to device\n",
    "    image, numerical_features = image.to(device), numerical_features.to(device)\n",
    "\n",
    "    # Get prediction\n",
    "    with torch.no_grad():\n",
    "        output = model(image, numerical_features)\n",
    "        predicted_class = torch.argmax(output, dim=1).item()\n",
    "\n",
    "    # Assuming you have the same label encoder used during training\n",
    "    class_mappings = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "\n",
    "    # Reverse mapping: index -> class name\n",
    "    index_to_class = {v: k for k, v in class_mappings.items()}\n",
    "\n",
    "    # Get class name from predicted index\n",
    "    predicted_label = index_to_class.get(predicted_class, \"Unknown\")\n",
    "\n",
    "    return predicted_label\n",
    "\n",
    "# Test the function\n",
    "image_path = r\"C:\\Users\\Samridhaa\\OneDrive\\Desktop\\DL Package\\color\\Grape___Leaf_blight_(Isariopsis_Leaf_Spot)\\fdcc77e7-78cc-4546-aae3-a0c8bd9a3427___FAM_L.Blight 4820.JPG\"\n",
    "result = predict(image_path)\n",
    "print(f\"Prediction: {result}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
